<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: GSOC2013 | SciRuby]]></title>
  <link href="http://sciruby.com/blog/categories/gsoc2013/atom.xml" rel="self"/>
  <link href="http://sciruby.com/"/>
  <updated>2017-10-23T20:55:53+09:00</updated>
  <id>http://sciruby.com/</id>
  <author>
    <name><![CDATA[SciRuby]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Some words from GSoC 2013 alumni]]></title>
    <link href="http://sciruby.com/blog/2014/01/28/gsoc-alumni/"/>
    <updated>2014-01-28T16:07:00+09:00</updated>
    <id>http://sciruby.com/blog/2014/01/28/gsoc-alumni</id>
    <content type="html"><![CDATA[<p>In 2013, SciRuby was a mentoring organization for the Google Summer of Code. We
asked our alumni:</p>

<p>1) How did you experience GSoC/SciRuby and what has it brought you?</p>

<p>2) What advice would you give new applicants?</p>

<p>Monica Dragan from Romania worked on <a href="https://github.com/monicadragan/GeneValidator">gene validation</a>, see also her
<a href="http://gene-prediction.blogspot.nl/2013/08/start-using-our-gene-validation-tool.html">blog</a>. Actually, Monica
was part of a different GSoC organisation,
<a href="http://informatics.nescent.org/wiki/Phyloinformatics_Summer_of_Code_2013">PhyloSoC</a>,
but also participated in our Ruby-centric meetings and code reviews. She shared
her SciRuby GSoC experience:</p>

<p class="note"><strong>Monica:</strong>
During the GSoC period I developed a bioinformatics tool written in Ruby. First of all I learned a new programming
language, as I had no experience with Ruby before. On this GSoC occasion I had the opportunity to get in touch with the
community and I met people passionate about their work, with whom I continued
 the collaboration afterwards. But what I really gained from this experience is that I increased my enthusiasm about
 bioinformatics and I confirmed myself that this is the field I want to focus on in the next years.
</p>


<p>Alberto Arrigoni from Italy worked on <a href="http://sciruby.com/blog/2013/09/24/gsoc-2013-data-mining-in-jruby-with-ruby-band/">data mining and machine learning algorithms for Ruby</a> and shared
his GSoC experience:</p>

<p class="note"><strong>Alberto:</strong>
As a PhD student in the field of bioinformatics, my GSOC experience was very exciting and useful at different levels. On a training level, I had the
unique chance to learn more in depth some topics of machine learning I had
wanted to explore in the past, but never had quite the opportunity or the
resources. On a more technical level, I appreciated the support of the GSOC
mentors and the Sciruby community, which counts numerous experts and a very
active mailing list.
</p>


<p>Ankur Goel from India worked on
<a href="http://rubygems.org/gems/statsample-timeseries">statsample-timeseries</a> for Ruby.
Ankur shared,</p>

<p class="note"><strong>Ankur:</strong>
It was the best learning experience. I learnt quite a lot of statistics while
working on my TimeSeries extension; after GSoC, I picked up Machine Learning
course and I was able to relate it to very easily after working on regression
techniques in GLM extension. I can't thank enough for the opportunity provided
and the trust endowed by my mentor on me. Learning to write quality code and
getting reviews was a cherry on cake! 
</p>


<p>Will Strinz from Madison, USA, worked on <a href="http://localhost:4000/blog/2013/10/12/ruby-and-the-semantic-web-rdf-sparql-publisci/">RDF generators for Ruby</a> for the
semantic web:</p>

<p class="note"><strong>Will:</strong>
GSoC 2013 was a new experience for me in terms of managing my own time,
planning my own project, and keeping up consistent interaction with my mentors
across time zones. Despite a decent amount of prior experience with Ruby, it
was also a challenge and an opportunity for me to really understand the tools
and practices I knew, and learn to use the ones I wasn't familiar with.

As for what it's brought me, aside from a job I secured partly through skills
and project portfolio I gained during GSoC, and the power of knowing how to do
just about any programming task using Ruby, I learned a lot about how to manage
a project and interact with people in the real world.

Communicating properly and in a timely manner over email and other asynchronous
services is absolutely critical to the work I do now, and a lot harder than
people make it out to be. Staying in touch with my mentors and making sure we
were all on the same page about my project was something I spent a lot of time
on, and in doing so I gained a lot of comfort with the process.

Additionally, GSoC was my first true experience designing a large piece of
software, where I couldn't just give up and trash it when the code started
getting messy or confusing. It really forced me to adopt good practices around
testing and organization, especially since I had better programmers than myself
looking over my work.

Software architecture is something you just don't learn in college level CS
courses, and by the time I'd graduated, I'd started hearing a lot of my CS
professors saying this too. Some day in the future, maybe soon, there will be
classes taught about just this subject, but for now there's no better way to
learn about it than by working on a real project, with some accountability and
motivation to actually get it done.


</p>


<p>Our alumni give new GSoC applicants the following advice:</p>

<p class="note"><strong>Monica:</strong>
GSoC is a great experience that you should try as a student! What is cool about GSoC is that you work on the project you are keen on and manage your time as
 you wish. Also, working remotely involves additional challenges. In the end you improve your experience and get to know a lot of new and great people.

</p>




<p class="note"><strong>Alberto:</strong>

I think one of the best features offered by the GSOC is the possibility to
collaborate with (and learn from) people who share the same scientific
interests and have very different backgrounds and skills. Though this may be
somewhat 'expected' for mentors, I was also lucky to find other GSOC students
willing to bond and share experiences and opinions. My advice is to be
cooperative and try to learn as much as possible from/with them!  

</p>




<p class="note"><strong>Ankur:</strong>
Work really hard. Do your homework before you ask questions or before quoting
anything in proposal. Writing a good proposal is necessary, and you must really
be aware of what you are writing - a good research is necessary. SciRuby
community members are readily available to help you at mailing list and #sciruby channel. A thorough discussion with the mentor will help you out.
</p>




<p class="note"><strong>Will:</strong>
To new applicants this year I'd stress one thing above all else; get in
touch with people on the sciruby mailing list. Introduce yourself as soon as
possible, and start discussing your project ideas when you have something in
mind. People on the mailing list are very friendly and helpful, so don't be
afraid to start a conversation, but also expect constructive criticism of your
proposals.

Answering any questions or concerns promptly and thoroughly not only shows that
your know your stuff and are passionate about your project, it also shows that
you are a good fit for GSoC in general. Don't assume you're in just because
you've had a good dialogue, but plan and communicate as though you are; don't
wait for the project to start to fill in details or contact your prospective
mentors personally.

Once you've submitted a proposal, all of this goes double. The closer you get
to the deadline, the less time there will be to polish your application and
respond to questions, so make sure you're doing it quickly and effectively.
</p>


<p>Our SciRuby GSoC alumni added:</p>

<p class="note"><strong>Monica:</strong>
If I don't join this year, I wish you good luck with the new students!
</p>




<p class="note"><strong>Ankur:</strong>
I will be happy to sign up again as student, this year!
</p>




<p class="note"><strong>Will:</strong>
I know I've said this already, but GSoC last year was a defining moment in my
path to becoming a software developer, career-wise sure, but more importantly
in the coder vs hacker vs computer scientist vs software developer sense. If
there's anything I can do to get involved this year, I'll be available.<p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Statistics with Ruby: Time Series and General Linear Models]]></title>
    <link href="http://sciruby.com/blog/2013/11/07/statistics-with-ruby-time-series-and-general-linear-models/"/>
    <updated>2013-11-07T13:15:00+09:00</updated>
    <id>http://sciruby.com/blog/2013/11/07/statistics-with-ruby-time-series-and-general-linear-models</id>
    <content type="html"><![CDATA[<p class="note"><strong>Editor's Note:</strong> This is the third of four blog posts detailing our Google Summer of
Code 2013 students' work, edited by John Woods.</p>




<p class="note"><strong>Gem Maintainer's Note:</strong> These gems have changed recently. Edits reflect the changes.</p>


<h2>Introduction</h2>

<p><a href="https://github.com/clbustos/statsample/">Statsample</a> is a basic and advanced statistics suite in Ruby. It attempts to support JRuby and MRI/YARV equally, and also provides pure Ruby implementations for many functions.</p>

<p>Statsample is a ruby gem for statistical analysis in ruby.</p>

<p>It includes a rich API, except for problems involving time series and generalized linear models (GLM), for which the functionality was rather basic.</p>

<p>So, in this <a href="https://www.google-melange.com/gsoc/homepage/google/gsoc2013">Google Summer of Code 2013</a> program, working on the SciRuby Project, I released two extensions:</p>

<ul>
<li><a href="http://github.com/sciruby/statsample-timeseries">Statsample TimeSeries</a></li>
<li><a href="https://github.com/sciruby/statsample-glm">Statsample GLM</a></li>
</ul>


<p>These gems aim to take Statsample further and incorporate various functionalities and estimation techniques on continuous data.</p>

<h2>Statsample TimeSeries</h2>

<p><a href="https://rubygems.org/gems/statsample-timeseries"><em>Statsample TimeSeries</em></a> is equipped with a variety of operations. A few of those functionalities are:</p>

<ul>
<li>_<a href="http://en.wikipedia.org/wiki/Autocorrelation">Autocorrelation</a> of series: For finding repeating patterns (like a periodic signal) in noisy data or for identifying persistence (if it rained today, will it rain tomorrow?).</li>
<li><a href="http://en.wikipedia.org/wiki/Autoregressive_moving_average_model">Autoregressive and Moving Average</a>: Autoregressive models (AR and ARMA) are useful for describing random processes such as found in nature and economics believed to be
predictable from past behavior (e.g., El Niño, the stock market).</li>
<li><a href="http://en.wikipedia.org/wiki/Partial_autocorrelation_function">Partial autocorrelation</a> with Yule&ndash;Walker, a method for calculating the coefficients of autoregressive models.</li>
<li><a href="http://en.wikipedia.org/wiki/Levinson_recursion">Levinson&ndash;Durbin</a> estimation: for <a href="http://www.mathworks.com/help/dsp/ref/levinsondurbin.html">solving linear equations</a> involving a <a href="http://en.wikipedia.org/wiki/Toeplitz_matrix">Toeplitz matrix</a>, such as in signal processing or cyclic signals.</li>
<li><a href="http://en.wikipedia.org/wiki/Kalman_filter">Kalman filtering</a> (or linear quadratic estimation): often used for determining position and motion of a moving object based on sensor information (e.g., for drawing a vehicle's position on a map using GPS data, or for aircraft or spacecraft navigation based on sensor inputs)</li>
</ul>


<p>To get your hands dirty,</p>

<ul>
<li>Install Statsample with <code>gem install statsample</code>.</li>
<li>Next, install the TimeSeries extension with <code>gem install statsample-timeseries</code>.</li>
</ul>


<p>EDIT: Statsample-timeseries now uses <a href="www.github.com/v0dro/daru/">daru</a> for data storage and cleaning. Thus all ephemeral time series statistics functions (moving average, acf, etc.) have been moved to Daru::Vector, which can be indexed on a DateTimeIndex, which lets you access data indexed by a time stamp. See the <a href="https://github.com/v0dro/daru/blob/master/README.md">daru README</a> for examples.</p>

<p><code>Statsample::TimeSeries::Series</code> has been deprecated in favour of <code>Daru::Vector</code>.</p>

<p>To demonstrate:
```ruby</p>

<p>require 'daru'
require 'statsample-timeseries'</p>

<p>ts = Daru::Vector.new(100.times.map { rand(100) }, index: Daru::DateTimeIndex.date_range(:start => '2012-2', :periods => 100))
ts.acf # Calculate auto-correlation
ts.pacf # Calculate partial autocorrelation</p>

<h1>Partial autocorrelation with 11 lags by maximum likelihood estimation</h1>

<p>ts.pacf(11, 'mle')
ts.ar # Autoregressive coefficients</p>

<h1>ARIMA(2, 1, 1)</h1>

<p>k_obj = Statsample::TimeSeries.arima(ts, 2, 1, 1)
k_obj.ar # autoregressive coefficients
k_obj.ma # moving average coefficients</p>

<p>```</p>

<h2>Statsample GLM</h2>

<p><a href="https://rubygems.org/gems/statsample-glm"><em>Statsample GLM</em></a> includes many helpful regression techniques, which can be used for regression analysis on data.
Some of those techniques are:</p>

<ul>
<li><a href="http://en.wikipedia.org/wiki/Poisson_regression">Poisson Regression</a>: used to model contingency tables and counts</li>
<li><a href="http://en.wikipedia.org/wiki/Logistic_regression">Logistic Regression</a></li>
<li>Exponential Regression: one case of <a href="http://en.wikipedia.org/wiki/Nonlinear_regression">nonlinear regression</a> (examples might include the <a href="http://mathbits.com/MathBits/TISection/Statistics2/exponential.htm">temperature of a cup of coffee</a> left in a cold room, or the decay of an orbit)</li>
<li><a href="http://en.wikipedia.org/wiki/Iteratively_reweighted_least_squares">Iteratively Reweighted Least Squares</a>: used to mitigate the effects of outliers</li>
</ul>


<p>The top level module for regression techniques is <code>Statsample::GLM</code>.</p>

<p>Using it is as simple as ever:</p>

<ul>
<li>First, install <code>statsample</code> by <code>gem install statsample</code>.</li>
<li>Then, install GLM by <code>gem install</code>statsample-glm`.</li>
</ul>


<p>Let's get started:</p>

<p>```ruby</p>

<p>require 'daru'
require 'statsample-glm'</p>

<h1>Create the datasets:</h1>

<p>x1 = Daru::Vector.new([0.537322309644812,-0.717124209978434,-0.519166718891331,0.434970973986765,-0.761822002215759,1.51170030921189,0.883854199811195,-0.908689798854196,1.70331977539793,-0.246971150634099,-1.59077593922623,-0.721548040910253,0.467025703920194,-0.510132788447137,0.430106510266798,-0.144353683251536,-1.54943800728303,0.849307651309298,-0.640304240933579,1.31462478279425,-0.399783455165345,0.0453055645017902,-2.58212161987746,-1.16484414309359,-1.08829266466281,-0.243893919684792,-1.96655661929441,0.301335373291024,-0.665832694463588,-0.0120650855753837,1.5116066367604,0.557300353673344,1.12829931872045,0.234443748015922,-2.03486690662651,0.275544751380246,-0.231465849558696,-0.356880153225012,-0.57746647541923,1.35758352580655,1.23971669378224,-0.662466275100489,0.313263561921793,-1.08783223256362,1.41964722846899,1.29325100940785,0.72153880625103,0.440580131022748,0.0351917814720056, -0.142353224879252])
x2 = Daru::Vector.new([-0.866655707911859,-0.367820249977585,0.361486610435,0.857332626245179,0.133438466268095,0.716104533073575,1.77206093023382,-0.10136697295802,-0.777086491435508,-0.204573554913706,0.963353531412233,-1.10103024900542,-0.404372761837392,-0.230226345183469,0.0363730246866971,-0.838265540390497,1.12543549657924,-0.57929175648001,-0.747060244805248,0.58946979365152,-0.531952663697324,1.53338594419818,0.521992029051441,1.41631763288724,0.611402316795129,-0.518355638373296,-0.515192557101107,-0.672697937866108,1.84347042325327,-0.21195540664804,-0.269869371631611,0.296155694010096,-2.18097898069634,-1.21314663927206,1.49193669881581,1.38969280369493,-0.400680808117106,-1.87282814976479,1.82394870451051,0.637864732838274,-0.141155946382493,0.0699950644281617,1.32568550595165,-0.412599258349398,0.14436832227506,-1.16507785388489,-2.16782049922428,0.24318371493798,0.258954871320764,-0.151966534521183])</p>

<p>y = Daru::Vector.new([0,0,1,0,1,1,1,1,0,1,1,1,1,0,1,0,1,1,0,1,0,1,1,1,1,0,0,1,1,0,0,1,0,0,1,1,0,0,1,1,0,1,1,1,1,0,0,0,1,1])</p>

<p>x = Daru::DataFrame.new({"x1"=>x1,"x2"=>x2})</p>

<p>obj = Statsample::GLM.compute(x, y, :binomial)</p>

<h1>=> Returns logistic regression object</h1>

<p>```
The <a href="http://rubydoc.info/gems/statsample-glm/Statsample/Regression">documentation and API details is available here</a></p>

<p>We have some more plans for GLM module. First in the list is to make the algorithms work with singular value decomposition, because manual inversion of matrices is not fun for larger values in a Poisson regression.</p>

<h2>Conclusion</h2>

<p>I have <a href="http://ankurgoel.com">blogged about most of the functionalities</a>; additional information is available there.</p>

<p>For more updated use cases refer to the notebooks in the respective project READMEs.</p>

<p>Please explore and use the libraries; I eagerly await your input, suggestions and questions. Feel free to leave any questions on <a href="http://github.com/SciRuby/statsample-glm/issues">the Statsample GLM tracker</a> or <a href="[the%20Statsample%20GLM%20tracker](http://github.com/SciRuby/statsample-glm/issues">the Statsample TimeSeries tracker</a>.</p>

<p>I had an amazing summer!</p>

<p>Stay tuned and Enjoy.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Ruby and the Semantic Web, RDF, and SPARQL: PubliSci]]></title>
    <link href="http://sciruby.com/blog/2013/10/12/ruby-and-the-semantic-web-rdf-sparql-publisci/"/>
    <updated>2013-10-12T16:36:00+09:00</updated>
    <id>http://sciruby.com/blog/2013/10/12/ruby-and-the-semantic-web-rdf-sparql-publisci</id>
    <content type="html"><![CDATA[<p class="note"><strong>Editor's Note:</strong> This is the second of four blog posts detailing our Google Summer of
Code 2013 students' work. I edited it to include a very incomplete list of public RDF repositories. &mdash;John Woods</p>


<h2>Introduction</h2>

<p>Across all fields and disciplines, contemporary scientists are faced with a massive and growing volume of data. It often
won't fit in a lab notebook, and there is a pressing need to share it more quickly and widely than publication in a
journal article would allow for. Database software is one great solution for storage of such data, but relational
databases become brittle in the face of changes or new information, do not play nicely with other databases or data
derived from such databases, and may not be fully machine (or human) readable without pre-existing knowledge.</p>

<p>Meanwhile, the Internet is an extremely useful place to discover and share useful information, but it is essentially
built around linked documents, rather than pure data, and so our primary mechanism for sharing data is as HTML or text.</p>

<p>RDF and related technologies propose to provide the means to move beyond a web of documents to a web of data. Along
the way, these technologies may address many of the problems with conventional relational databases (e.g., SQL). At its
core, RDF defines an extremely flexible method for representing data on the web &mdash; which is nonetheless
unambiguously defined, without any external context, and can be linked to other data as web documents link to each
other. Because RDF data can be understood as either a set of subject&ndash;predicate&ndash;object statements or a
directed graph with labeled edges, a number of supporting standards and tools that have grown up around it to provide
powerful storage and access methods that are often easier to implement and use than those associated with relational
databases and the document-based web.</p>

<h2>Enter PubliSci</h2>

<p>This summer I created a Ruby gem, <a href="http://github.com/sciruby/publisci">PubliSci</a>, to facilitate data publication and interaction using
the <a href="https://en.wikipedia.org/wiki/Semantic_web">Semantic Web</a>. The format offers a unified way to share and combine
information from multiple sources, support for machine learning tools,
a <a href="https://en.wikipedia.org/wiki/SPARQL">flexible query language</a> that makes application integration easy, and the
backing of the World Wide Web Consortium (W3C) and other standards-setting bodies.</p>

<p>The PubliSci gem comprises a set of parsers for converting various input formats using
the <a href="http://semanticweb.com/w3c-publishes-last-call-working-drafts-for-rdf-data-cube-dcat_b35950">RDF Data Cube vocabulary</a>, and
a Ruby interface for defining new ones. Since the relationship between external datasets and semantic web formats is
sometimes up to interpretation, a domain-specific language is included to allow end users to resolve ambiguities and
provide additional metadata.</p>

<p>Along with the conversion tool, a standalone server is available as an extension to the gem that simplifies setting up and interacting
with RDF data stores. The server allows import, export, querying, and management of external <a href="https://en.wikipedia.org/wiki/Triplestore">triplestores</a> such as
<a href="http://4store.org/">4store</a>, and supports both cross-domain access and content negotiation so the gem can be accessed
using Javascript or other applications.</p>

<p class="note"><strong>Triplestores</strong> are databases for the storage and retrieval of <strong>triples</strong>,
which are typically subject&ndash;object&ndash;predicate relationships (e.g., <i>Bob knows Fred</i>).</p>


<p>If you'd like to contribute, the <a href="https://github.com/sciruby/publisci">source code is available on Github</a>, and <a href="http://gsocsemantic.wordpress.com/2013/08/05/bio-publisci/">a broad
outline of the to do list can be had as well</a>.</p>

<h2>Usage</h2>

<p>Once you've done <code>gem install publisci</code>, you can require the gem in the normal way (<code>require 'publisci'</code>). To invoke the
domain-specific language, you'll also want to include the <code>DSL</code> module:</p>

<pre><code>require 'publisci'
include PubliSci::DSL
</code></pre>

<p>Input data can be specified like so:</p>

<pre><code># Specify input data
data do
  # Use local or remote paths to point to the data file you want to load:
  source 'https://github.com/wstrinz/publisci/raw/master/spec/csv/bacon.csv'

  # Specify datacube properties.
  dimension 'producer', 'pricerange'
  measure 'chunkiness'

  # Set parser-specific options.
  option 'label_column', 'producer'
end
</code></pre>

<p>You can provide meta-data on your dataset as well.</p>

<pre><code>metadata do
  dataset 'bacon'
  title 'Bacon dataset'
  creator 'Will Strinz'
  description 'some data about bacon'
  date '1-10-2010'
end
</code></pre>

<p>Sending the data to a repository is simple.</p>

<pre><code># Send output to an RDF::Repository
#  can also use 'generate_n3' to output a turtle string
repo = to_repository
</code></pre>

<p>SPARQL queries can be run on the dataset using the <code>QueryHelper</code> module.</p>

<pre><code># run SPARQL queries on the dataset
PubliSci::QueryHelper.execute('select * where {?s ?p ?o} limit 5', repo)
</code></pre>

<p>Finally, data can be exported in other formats, such as ARFF:</p>

<pre><code># export in other formats
PubliSci::Writers::ARFF.new.from_store(repo)
</code></pre>

<h2>Some places to look for RDF repositories</h2>

<ul>
<li>Social sciences and economics: <a href="http://wiki.planet-data.eu/web/Datasets">PlanetData wiki: Datasets</a>, <a href="http://270a.info/">270a Linked Dataspaces</a></li>
<li>Chemistry: <a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3118380/">Resource description framework technologies in chemistry</a></li>
<li>Molecular biology: <a href="http://www.ebi.ac.uk/rdf/">EMBL-EBI: Current RDF Resources</a>, <a href="http://bio2rdf.org/">Bio2RDF</a>,
<a href="http://www.geneontology.org/GO.format.rdfxml.shtml">Gene Ontology</a></li>
<li>Ecology: <a href="http://www.bbc.co.uk/nature/feedsanddata">BBC Wildlife Finder</a></li>
<li>General: <a href="http://dataincubator.org/">Data Incubator: Growing the Web of Data</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[GSOC 2013: Data mining in JRuby with Ruby Band]]></title>
    <link href="http://sciruby.com/blog/2013/09/24/gsoc-2013-data-mining-in-jruby-with-ruby-band/"/>
    <updated>2013-09-24T10:44:00+09:00</updated>
    <id>http://sciruby.com/blog/2013/09/24/gsoc-2013-data-mining-in-jruby-with-ruby-band</id>
    <content type="html"><![CDATA[<p class="note"><strong>Editor's Note:</strong> This is the first of four blog posts detailing
our Google Summer of Code 2013 students' work, edited by John Woods.</p>


<p>In the context of the Google Summer of Code 2013, I have developed a Ruby gem called <a href="https://github.com/arrigonialberto86/ruby-band">Ruby Band</a>
that makes some selected Java software for data mining and machine learning applications available to the JRuby/Ruby
users. This project complements existing software already developed for SciRuby by adding support for the Weka Toolkit
and general functions included in the Apache Commons Math library.</p>

<p>As Weka does, Ruby Band features a comprehensive collection of data preprocessing and modeling techniques, and supports
several standard data mining tasks, more specifically: data pre-processing (filtering), clustering, classification,
regression, and feature selection.</p>

<p>All of Ruby Band's techniques have been built on the assumption that the data is
available as a single flat file or relation, where each datum is described by a fixed number of attributes. The
loaded datasets are stored in Weka Instances objects, which are used as 'core' data types for the interactions with
other software (Apache Commons Math) or platforms.</p>

<p>Originally, Ruby Band was called Ruby Mining. I renamed it Ruby Band, as I imagine
different software sources (Weka, Apache, etc.) working as a whole, like in a real band. Ruby Band has been designed
with a modular structure, so that it can be easily extended and integrated with other Java software. The Core module is
allows data types from different sources to be defined and integrated using converter methods;
functionalities from each piece of additional software are independently imported. This structure increases the
extensibility of the product, as in the future other developers may add functionalities according to their needs.</p>

<p>Though Ruby Band provides full support for the greatest part of the Weka APIs, some topics still need to be addressed
properly. As I coded, I utilized the Weka Java APIs documentation as my roadmap; if you want to contribute,
<a href="http://weka.wikispaces.com/Use+WEKA+in+your+Java+code">go see what is still missing</a>. The best and easiest way
to introduce a new functionality into the Ruby Band framework is to write up a pertinent Cucumber test, as a number of
Weka recipes have been posted online by the creators.</p>

<p>The beta version of Ruby Band has already been released for general use on Rubygems (<code>gem install ruby-band</code>).</p>

<p>This is a quick example of how to train a classifier on a dataset parsed from an ARFF file:</p>

<pre><code>require 'ruby-band'

# parse a dataset
dataset = Core::Parser.parse_ARFF(my_file.arff)

# initialize and train a classifier
classifier = Weka::Classifier::Lazy::KStar::Base.new do
  set_options '-M d'
  set_data dataset
  set_class_index 4
end

# cross-validate the trained classifier
puts classifier.cross_validate(3)
</code></pre>
]]></content>
  </entry>
  
</feed>
